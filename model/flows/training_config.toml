# PII Detection Model Training Configuration
# All pipeline settings are controlled via this file.

[model]
name = "answerdotai/ModernBERT-base"

[training]
num_epochs = 15  # Reduced from 40 to prevent overfitting
batch_size = 64
learning_rate = 3e-5
max_sequence_length = 8192
weight_decay = 0.02  # Increased from default 0.01 for better regularization
eval_steps = 250  # Evaluate more frequently to catch overfitting early (was 500)
save_steps = 250  # Save checkpoints more frequently

# Early stopping settings
early_stopping_enabled = true
early_stopping_patience = 2  # Reduced from 3 - stop sooner when not improving
early_stopping_threshold = 0.005  # More sensitive to detect plateaus earlier

[paths]
# Directory containing JSON training samples (relative to working directory or absolute)
training_samples_dir = "model/dataset/training_samples"
output_dir = "model/trained"

[labelstudio]
# Label Studio base url
base_url = "http://localhost:8080"
# ID of the label studio project
project_id = 5


[data]
# Limit samples for quick iteration (0 = use all)
subsample_count = 0

[pipeline]
# Skip Label Studio export and use existing data from paths.training_samples_dir
skip_export = true
# Skip ONNX quantization (only works on Linux)
skip_quantization = false
# Skip model signing
skip_signing = false

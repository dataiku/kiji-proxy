# PII Detection Model Training Configuration
# All pipeline settings are controlled via this file.

[model]
name = "answerdotai/ModernBERT-base"

[training]
num_epochs = 20  # Reduced from 40 to prevent overfitting
batch_size = 128
learning_rate = 3e-5
max_sequence_length = 8192
weight_decay = 0.02  # Increased from default 0.01 for better regularization
# Evaluation and saving now happen after every epoch (configured in trainer.py)

# Focal Loss settings (critical for handling class imbalance with long sequences)
# Most tokens are "O" (non-PII), Focal Loss helps focus on the rare PII tokens
focal_gamma = 2.0  # Focusing parameter (0=standard CE, 2=typical for detection tasks)
focal_alpha = 0.75  # Balance factor - upweights positive (PII) classes
label_smoothing = 0.1  # Prevents overconfident predictions

# Multi-task loss weights
pii_loss_weight = 1.0  # Primary task
coref_loss_weight = 0.5  # Secondary task (reduced weight)

# Early stopping settings
early_stopping_enabled = true
early_stopping_patience = 5  # Reduced from 3 - stop sooner when not improving
early_stopping_threshold = 0.001  # More sensitive to detect plateaus earlier

[paths]
# Directory containing JSON training samples (relative to working directory or absolute)
training_samples_dir = "model/dataset/training_samples"
output_dir = "model/trained"

[labelstudio]
# Label Studio base url
base_url = "http://localhost:8080"
# ID of the label studio project
project_id = 5


[data]
# Limit samples for quick iteration (0 = use all)
subsample_count = 0

[pipeline]
# Skip Label Studio export and use existing data from paths.training_samples_dir
skip_export = true
# Skip ONNX quantization (only works on Linux)
skip_quantization = false
# Skip model signing
skip_signing = false
